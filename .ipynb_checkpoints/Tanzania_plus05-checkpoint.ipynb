{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidated workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import initial libraries and data file. N.B. The data already had season_recorded added as a composite variable, by me, earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 23)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plot\n",
    "import seaborn as sns\n",
    "\n",
    "# check select_data\n",
    "df = pd.read_csv('/Users/RAhmed/data store/Wesleyan_Capstone/select_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanzania - data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plot\n",
    "import seaborn as sns\n",
    "\n",
    "# check select_data\n",
    "df = pd.read_csv('/Users/RAhmed/data store/Wesleyan_Capstone/all_numeric201808292240.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn's decision trees and random forests need categorical data changed into integers. See, e.g,: https://stackoverflow.com/questions/38108832/passing-categorical-data-to-sklearn-decision-tree\n",
    "\n",
    "The above data set has already had this done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date_recorded', 'season_recorded', 'gps_height', 'installer',\n",
       "       'longitude', 'latitude', 'basin', 'region_code', 'population',\n",
       "       'public_meeting', 'scheme_management', 'permit', 'wpt_age',\n",
       "       'construction_year', 'extraction_type_group', 'management_group',\n",
       "       'payment_type', 'water_quality', 'quantity_group', 'source_type',\n",
       "       'source_class', 'waterpoint_type_group', 'status_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_train.shape: (47520, 18)\n",
      "pred_test.shape: (11880, 18)\n",
      "tar_train.shape: (47520,)\n",
      "tar_test.shape: (11880,)\n"
     ]
    }
   ],
   "source": [
    "chosen_predictors = ['season_recorded', 'gps_height', 'installer', 'basin', 'region_code', 'population',\n",
    "                     'public_meeting', 'scheme_management', 'permit', 'wpt_age','construction_year', \n",
    "                     'extraction_type_group', 'management_group', 'payment_type', 'water_quality', \n",
    "                     'quantity_group', 'source_type', 'waterpoint_type_group'\n",
    "                    ]\n",
    "\n",
    "predictors = df[chosen_predictors]\n",
    "targets = df['status_group']\n",
    "\n",
    "# train/test split\n",
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, targets, test_size=.2)\n",
    "\n",
    "print(\"pred_train.shape:\", pred_train.shape)\n",
    "print(\"pred_test.shape:\", pred_test.shape)\n",
    "print(\"tar_train.shape:\", tar_train.shape)\n",
    "print(\"tar_test.shape:\", tar_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier model with a decision tree, on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[5120  343  891]\n",
      " [ 354  338  179]\n",
      " [ 987  173 3495]]\n",
      "Accuracy score:\n",
      "0.7536195286195286\n"
     ]
    }
   ],
   "source": [
    "# Build model on training data; initiate classifier from sklearn, then fit it with the training data\n",
    "classifier=DecisionTreeClassifier()\n",
    "classifier=classifier.fit(pred_train,tar_train)\n",
    "\n",
    "# predict for the test values and create confusion matrix\n",
    "predictions=classifier.predict(pred_test)\n",
    "print(\"Confusion matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(tar_test,predictions))\n",
    "print(\"Accuracy score:\")\n",
    "print(sklearn.metrics.accuracy_score(tar_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying again, to play with parameters, experiment, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7553030303030303"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with hyper-parameters. Also have varied the wording of the code from that in the MOOC. \n",
    "# (Just to check all in order with exceptionally high result.)\n",
    "# train/test split\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors[:], targets[:], test_size=.2)\n",
    "\n",
    "# Build model on training data; initiate classifier from sklearn, then fit it with the training data\n",
    "model = DecisionTreeClassifier(max_depth=None)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For confusion matrix, N.B. that:\n",
    "\n",
    "functional = 0\n",
    "\n",
    "functional_needs_repair = 1\n",
    "\n",
    "non-functional = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred functional</th>\n",
       "      <th>Predicted func_need_repair</th>\n",
       "      <th>Predicted non_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True functional</th>\n",
       "      <td>5148</td>\n",
       "      <td>373</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True func_need_repair</th>\n",
       "      <td>353</td>\n",
       "      <td>366</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True non_func</th>\n",
       "      <td>879</td>\n",
       "      <td>200</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Pred functional  Predicted func_need_repair  \\\n",
       "True functional                   5148                         373   \n",
       "True func_need_repair              353                         366   \n",
       "True non_func                      879                         200   \n",
       "\n",
       "                       Predicted non_func  \n",
       "True functional                       945  \n",
       "True func_need_repair                 157  \n",
       "True non_func                        3459  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict),\n",
    "    columns=['Pred functional', 'Predicted func_need_repair', 'Predicted non_func'],\n",
    "    index=['True functional', 'True func_need_repair', 'True non_func']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7553030303030303"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reprint for convenience\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key ingredient: see which features are most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gps_height', 0.21137366969202878),\n",
       " ('wpt_age', 0.161596418723216),\n",
       " ('quantity_group', 0.15625972345481492),\n",
       " ('waterpoint_type_group', 0.07989051614506813),\n",
       " ('installer', 0.05551817301162601),\n",
       " ('region_code', 0.043381341820464256),\n",
       " ('payment_type', 0.041610236404126505),\n",
       " ('population', 0.035799532888753094),\n",
       " ('extraction_type_group', 0.0334683228144356),\n",
       " ('construction_year', 0.0306857678054853),\n",
       " ('source_type', 0.029017294952964533),\n",
       " ('scheme_management', 0.027798322018767793),\n",
       " ('basin', 0.02540525378348438),\n",
       " ('water_quality', 0.017607862289897216),\n",
       " ('permit', 0.01579272825581607),\n",
       " ('public_meeting', 0.012979489291717978),\n",
       " ('season_recorded', 0.01139977332904869),\n",
       " ('management_group', 0.010415573318284663)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = (dict(zip(X_train, model.feature_importances_)))\n",
    "sorted_items = sorted(importance.items(), key = lambda x: x[1], reverse=True)\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that visualising the decision tree is quite straight forward.\n",
    "\n",
    "There are two things one can initially do: limit or not limit maximum depth as folling example:\n",
    "model = DecisionTreeClassifier(max_depth=None)\n",
    "\n",
    "As below, push the image out to a tree.dot file. Find it on your computer amd then cut and paste the code into a web viewer/converter. See, e.g.:\n",
    "http://www.ilovefreesoftware.com/03/featured/free-online-dot-to-png-converter-websites.html https://dreampuf.github.io/GraphvizOnline/\n",
    "\n",
    "Right-clicking the image in GraphvizOnline, I could save the png to desktop.\n",
    "\n",
    "If you limit maximum depth, your decision tree may be small enough to fit on one page. Else, cut and paste a number of lines of code from the tree.dot file, making sure you finish as follows in the online converter, e.g.:\n",
    "\n",
    "...\n",
    "44 -> 54 ; \n",
    "}\n",
    "\n",
    "If you do limit the max depth the tree will be different, of course, than a full tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# visualise\n",
    "tree.export_graphviz(model, out_file='tree.dot') \n",
    "# cut and paste the tree.dot file info into webgraphviz.com in a browser. \n",
    "# (You can paste as many layers of the tree as you want. See notes above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a file\n",
    "# df.to_csv('/Users/RAhmed/data store/Wesleyan_Capstone/all_numeric201808292240.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Aside - do KNN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: 0.6771043771043771},\n",
       " {2: 0.679040404040404},\n",
       " {3: 0.6873737373737374},\n",
       " {4: 0.6861952861952862},\n",
       " {5: 0.6871212121212121},\n",
       " {6: 0.6813973063973064},\n",
       " {7: 0.682996632996633},\n",
       " {8: 0.6821548821548822},\n",
       " {9: 0.6824915824915825},\n",
       " {10: 0.6788720538720538},\n",
       " {11: 0.6771043771043771},\n",
       " {12: 0.6781144781144781},\n",
       " {13: 0.6758417508417508},\n",
       " {14: 0.6734006734006734}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import the Classifier.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "## Instantiate the model with 5 neighbors. \n",
    "knn_list = []\n",
    "for i in range(1,15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    ## Fit the model on the training data.\n",
    "    knn.fit(X_train, y_train)\n",
    "    ## See how the model performs on the test data.\n",
    "    knn.score(X_test, y_test)\n",
    "    ## Append to list.\n",
    "    knn_list.append({i: knn.score(X_test, y_test)})\n",
    "knn_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a global cross-validation approach on Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/machine_learning/model_evaluation/cross-validaton/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757979797979798"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With k-fold cross validation. \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=None)\n",
    "\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(model, # Classifier\n",
    "                             predictors, # Feature matrix\n",
    "                             targets, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "\n",
    "# Calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a hold out cross-validation approach on Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two differences: \n",
    "> i). do cross-validation on train set only (not against all), and predict against test set<br>\n",
    "> ii). experiment within the decision tree with various parameters\n",
    "\n",
    "N.B. cross_validation does not give a fitted model. There is a cross_val_predict, but I think it doesn;t test against a seprate hold out set. (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7652988215488217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7651515151515151"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With k-fold cross validation. \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, targets, test_size=.2)\n",
    "\n",
    "# Difference for this \n",
    "model = DecisionTreeClassifier(max_depth=20, criterion='gini', random_state=2, splitter='random')\n",
    "\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(model, # Classifier\n",
    "                             X_train, # Feature matrix\n",
    "                             y_train, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "\n",
    "# Calculate mean against train set!\n",
    "print(cv_results.mean())\n",
    "\n",
    "# So I have tweaked the 'model' (above) parameters to get the best model, \n",
    "# and can now test against the hold out set. ((Tweaked) Model has to be fitted)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ above cross validation tweaking has improved accuracy (against hold out) by some 1.5%, great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Random Forest approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary libraries\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "# feature importance\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "Confusion matrix:\n",
      "[[5619  210  637]\n",
      " [ 392  338  146]\n",
      " [ 908  125 3505]]\n",
      "Accuracy score:\n",
      "0.7964646464646464\n",
      "\n",
      "RandomForestClassifier relative feature importance:\n",
      "gps_height                                                         0.1821802097372602\n",
      "wpt_age                                                           0.15181877573977384\n",
      "quantity_group                                                     0.1276993841321722\n",
      "construction_year                                                 0.07191145627623537\n",
      "installer                                                         0.05964110750070234\n",
      "waterpoint_type_group                                             0.05698960579470149\n",
      "extraction_type_group                                              0.0546123771953428\n",
      "payment_type                                                     0.043689133821211576\n",
      "region_code                                                      0.042915515609313955\n",
      "population                                                        0.03953336898613709\n",
      "scheme_management                                                 0.02995419385349824\n",
      "basin                                                            0.029765977175965786\n",
      "source_type                                                       0.02920840730038602\n",
      "water_quality                                                    0.020188982841298126\n",
      "season_recorded                                                  0.018474479296781646\n",
      "permit                                                            0.01650522317376526\n",
      "public_meeting                                                   0.012989567976205738\n",
      "management_group                                                  0.01192223358924824\n",
      "\n",
      "EXTRA TREE\n",
      "Confusion matrix:\n",
      "[[5619  210  637]\n",
      " [ 392  338  146]\n",
      " [ 908  125 3505]]\n",
      "Accuracy score:\n",
      "0.7964646464646464\n",
      "\n",
      "ExtraTreesClassifier relative feature importance:\n",
      "gps_height                                                        0.18244819997210748\n",
      "wpt_age                                                           0.12531195917020185\n",
      "quantity_group                                                    0.11939397126107157\n",
      "construction_year                                                 0.08024419430932171\n",
      "waterpoint_type_group                                               0.068635969060856\n",
      "payment_type                                                      0.05522849744165685\n",
      "installer                                                         0.05318075238518122\n",
      "extraction_type_group                                             0.04490869135477996\n",
      "population                                                        0.04198559858625638\n",
      "region_code                                                      0.039806415654825976\n",
      "basin                                                            0.032615868202605265\n",
      "source_type                                                      0.029129106645164642\n",
      "scheme_management                                                0.028807257199093945\n",
      "season_recorded                                                   0.02290332581259422\n",
      "water_quality                                                    0.022078577265289008\n",
      "permit                                                            0.02194079652216954\n",
      "public_meeting                                                   0.016184963343204007\n",
      "management_group                                                  0.01519585581362036\n"
     ]
    }
   ],
   "source": [
    "# run Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier (sometimes use clf) is initiated\n",
    "classifier=RandomForestClassifier(n_estimators=25)\n",
    "# next step trains the model\n",
    "classifier=classifier.fit(X_train,y_train)\n",
    "# now we apply the classifier to the test data\n",
    "predictions=classifier.predict(X_test)\n",
    "\n",
    "# we look at confusion matrix and accuracy of prediction on test values\n",
    "print(\"RANDOM FOREST\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(y_test,predictions))\n",
    "print(\"Accuracy score:\")\n",
    "print(sklearn.metrics.accuracy_score(y_test, predictions))\n",
    "print()\n",
    "# display the relative importance of each attribute using RandomForestClassifier\n",
    "# make this more readable by having the names of the predictors and having sorted\n",
    "zipped = zip(predictors, classifier.feature_importances_)\n",
    "my_list = list(zipped)\n",
    "my_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "print('RandomForestClassifier relative feature importance:')\n",
    "for item in my_list:\n",
    "    print('{0:42} {1:>42}'.format(item[0], item[1]))\n",
    "\n",
    "# fit an Extra Trees model to the data (instead of Random Forest)\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "predictions=classifier.predict(X_test)\n",
    "print()\n",
    "print(\"EXTRA TREE\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(y_test,predictions))\n",
    "print(\"Accuracy score:\")\n",
    "print(sklearn.metrics.accuracy_score(y_test, predictions))\n",
    "print()\n",
    "# make this more readable by having the names of the predictors and having sorted\n",
    "zipped = zip(predictors, model.feature_importances_)\n",
    "my_list = list(zipped)\n",
    "my_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "print('ExtraTreesClassifier relative feature importance:')\n",
    "for item in my_list:\n",
    "    print('{0:42} {1:>42}'.format(item[0], item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do random forest with cross-validation and hold out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8127104377104377"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest with cross-validation and hold out set\n",
    "model = RandomForestClassifier(n_estimators=50, criterion='entropy', max_depth=18, \n",
    "                               bootstrap=True, oob_score=True, random_state=5)\n",
    "\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(model, # Classifier\n",
    "                             X_train, # Feature matrix\n",
    "                             y_train, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "\n",
    "# Calculate mean against train set!\n",
    "cv_results.mean()\n",
    "\n",
    "# Calculate mean against test set\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | Cross-validation | Hold-out set | Accuracy |\n",
    "| ---- | ---- | ---- | ---- |\n",
    "| KNN | no | yes | 68.8% |\n",
    "| Decision tree | no | yes | 75.5% |\n",
    "| Decision tree | yes | no | 75.8% |\n",
    "| Decision tree | yes | yes | 76.5% |\n",
    "| Random forest | no | yes | 79.6% |\n",
    "| Random forest | yes | yes | 81.2% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How could be improved: frequency encoding of variables; nearest neighbour for construction year?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
