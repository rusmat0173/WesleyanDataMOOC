{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidated workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import initial libraries and data file. N.B. The data already had season_recorded added as a composite variable, by me, earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 23)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plot\n",
    "import seaborn as sns\n",
    "\n",
    "# check select_data\n",
    "df = pd.read_csv('/Users/RAhmed/data store/Wesleyan_Capstone/select_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanzania - data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plot\n",
    "import seaborn as sns\n",
    "\n",
    "# check select_data\n",
    "df = pd.read_csv('/Users/RAhmed/data store/Wesleyan_Capstone/all_numeric201808292240.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn's decision trees and random forests need categorical data changed into integers. See, e.g,: https://stackoverflow.com/questions/38108832/passing-categorical-data-to-sklearn-decision-tree\n",
    "\n",
    "The above data set has already had this done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date_recorded', 'season_recorded', 'gps_height', 'installer',\n",
       "       'longitude', 'latitude', 'basin', 'region_code', 'population',\n",
       "       'public_meeting', 'scheme_management', 'permit', 'wpt_age',\n",
       "       'construction_year', 'extraction_type_group', 'management_group',\n",
       "       'payment_type', 'water_quality', 'quantity_group', 'source_type',\n",
       "       'source_class', 'waterpoint_type_group', 'status_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_train.shape: (47520, 18)\n",
      "pred_test.shape: (11880, 18)\n",
      "tar_train.shape: (47520,)\n",
      "tar_test.shape: (11880,)\n"
     ]
    }
   ],
   "source": [
    "chosen_predictors = ['season_recorded', 'gps_height', 'installer', 'basin', 'region_code', 'population',\n",
    "                     'public_meeting', 'scheme_management', 'permit', 'wpt_age','construction_year', \n",
    "                     'extraction_type_group', 'management_group', 'payment_type', 'water_quality', \n",
    "                     'quantity_group', 'source_type', 'waterpoint_type_group'\n",
    "                    ]\n",
    "\n",
    "predictors = df[chosen_predictors]\n",
    "targets = df['status_group']\n",
    "\n",
    "# train/test split\n",
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, targets, test_size=.2)\n",
    "\n",
    "print(\"pred_train.shape:\", pred_train.shape)\n",
    "print(\"pred_test.shape:\", pred_test.shape)\n",
    "print(\"tar_train.shape:\", tar_train.shape)\n",
    "print(\"tar_test.shape:\", tar_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier model with a decision tree, on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[5148  368  957]\n",
      " [ 358  322  173]\n",
      " [ 944  194 3416]]\n",
      "Accuracy score:\n",
      "0.747979797979798\n"
     ]
    }
   ],
   "source": [
    "# Build model on training data; initiate classifier from sklearn, then fit it with the training data\n",
    "classifier=DecisionTreeClassifier(random_state=2)\n",
    "classifier=classifier.fit(pred_train,tar_train)\n",
    "\n",
    "# predict for the test values and create confusion matrix\n",
    "predictions=classifier.predict(pred_test)\n",
    "print(\"Confusion matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(tar_test,predictions))\n",
    "print(\"Accuracy score:\")\n",
    "print(sklearn.metrics.accuracy_score(tar_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying again, to play with parameters, experiment, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7521885521885522"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with hyper-parameters. Also have varied the wording of the code from that in the MOOC. \n",
    "# (Just to check all in order with exceptionally high result.)\n",
    "# train/test split\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors[:], targets[:], test_size=.2)\n",
    "\n",
    "# Build model on training data; initiate classifier from sklearn, then fit it with the training data\n",
    "model = DecisionTreeClassifier(random_state=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For confusion matrix, N.B. that:\n",
    "\n",
    "functional = 0\n",
    "\n",
    "functional_needs_repair = 1\n",
    "\n",
    "non-functional = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred functional</th>\n",
       "      <th>Predicted func_need_repair</th>\n",
       "      <th>Predicted non_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True functional</th>\n",
       "      <td>5132</td>\n",
       "      <td>327</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True func_need_repair</th>\n",
       "      <td>363</td>\n",
       "      <td>325</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True non_func</th>\n",
       "      <td>925</td>\n",
       "      <td>206</td>\n",
       "      <td>3479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Pred functional  Predicted func_need_repair  \\\n",
       "True functional                   5132                         327   \n",
       "True func_need_repair              363                         325   \n",
       "True non_func                      925                         206   \n",
       "\n",
       "                       Predicted non_func  \n",
       "True functional                       947  \n",
       "True func_need_repair                 176  \n",
       "True non_func                        3479  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict),\n",
    "    columns=['Pred functional', 'Predicted func_need_repair', 'Predicted non_func'],\n",
    "    index=['True functional', 'True func_need_repair', 'True non_func']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7521885521885522"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reprint for convenience\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key ingredient: see which features are most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gps_height', 0.21044844539248103),\n",
       " ('wpt_age', 0.16360561952321392),\n",
       " ('quantity_group', 0.15839560334943248),\n",
       " ('waterpoint_type_group', 0.08013248594811606),\n",
       " ('installer', 0.06039435339448815),\n",
       " ('payment_type', 0.03934324506575694),\n",
       " ('region_code', 0.03571623680207435),\n",
       " ('population', 0.03515047466389715),\n",
       " ('scheme_management', 0.03151831813176631),\n",
       " ('extraction_type_group', 0.03134553922849094),\n",
       " ('construction_year', 0.03104788735871742),\n",
       " ('source_type', 0.028828106575916126),\n",
       " ('basin', 0.026575605946319532),\n",
       " ('water_quality', 0.016739476925291825),\n",
       " ('season_recorded', 0.016088793473268054),\n",
       " ('permit', 0.013308066569371781),\n",
       " ('management_group', 0.011000948322635491),\n",
       " ('public_meeting', 0.010360793328762375)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = (dict(zip(X_train, model.feature_importances_)))\n",
    "sorted_items = sorted(importance.items(), key = lambda x: x[1], reverse=True)\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that visualising the decision tree is quite straight forward.\n",
    "\n",
    "There are two things one can initially do: limit or not limit maximum depth as folling example:\n",
    "model = DecisionTreeClassifier(max_depth=None)\n",
    "\n",
    "As below, push the image out to a tree.dot file. Find it on your computer amd then cut and paste the code into a web viewer/converter. See, e.g.:\n",
    "http://www.ilovefreesoftware.com/03/featured/free-online-dot-to-png-converter-websites.html https://dreampuf.github.io/GraphvizOnline/\n",
    "\n",
    "Right-clicking the image in GraphvizOnline, I could save the png to desktop.\n",
    "\n",
    "If you limit maximum depth, your decision tree may be small enough to fit on one page. Else, cut and paste a number of lines of code from the tree.dot file, making sure you finish as follows in the online converter, e.g.:\n",
    "\n",
    "...\n",
    "44 -> 54 ; \n",
    "}\n",
    "\n",
    "If you do limit the max depth the tree will be different, of course, than a full tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# visualise\n",
    "tree.export_graphviz(model, out_file='tree.dot') \n",
    "# cut and paste the tree.dot file info into webgraphviz.com in a browser. \n",
    "# (You can paste as many layers of the tree as you want. See notes above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a file\n",
    "# df.to_csv('/Users/RAhmed/data store/Wesleyan_Capstone/all_numeric201808292240.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Aside - do KNN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: 0.6738215488215489},\n",
       " {2: 0.6712121212121213},\n",
       " {3: 0.6857744107744108},\n",
       " {4: 0.681986531986532},\n",
       " {5: 0.6885521885521886},\n",
       " {6: 0.6844276094276094},\n",
       " {7: 0.6792929292929293},\n",
       " {8: 0.6792929292929293},\n",
       " {9: 0.6807239057239057},\n",
       " {10: 0.6768518518518518},\n",
       " {11: 0.6751683501683502},\n",
       " {12: 0.6749158249158249},\n",
       " {13: 0.6690235690235691},\n",
       " {14: 0.6697811447811448}]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import the Classifier.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "## Instantiate the model with 5 neighbors. \n",
    "knn_list = []\n",
    "for i in range(1,15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    ## Fit the model on the training data.\n",
    "    knn.fit(X_train, y_train)\n",
    "    ## See how the model performs on the test data.\n",
    "    knn.score(X_test, y_test)\n",
    "    ## Append to list.\n",
    "    knn_list.append({i: knn.score(X_test, y_test)})\n",
    "knn_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a global cross-validation approach on Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/machine_learning/model_evaluation/cross-validaton/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757979797979798"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With k-fold cross validation. \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=None, random_state=2)\n",
    "\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=2)\n",
    "\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(model, # Classifier\n",
    "                             predictors, # Feature matrix\n",
    "                             targets, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "\n",
    "# Calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a hold out cross-validation approach on Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two differences: \n",
    "> i). do cross-validation on train set only (not against all), and predict against test set<br>\n",
    "> ii). experiment within the decision tree with various parameters\n",
    "\n",
    "N.B. cross_validation does not give a fitted model. There is a cross_val_predict, but I think it doesn;t test against a seprate hold out set. (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7645412457912457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.773989898989899"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With k-fold cross validation. \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, targets, test_size=.2)\n",
    "\n",
    "# Difference for this \n",
    "model = DecisionTreeClassifier(max_depth=20, criterion='gini', random_state=2, splitter='random')\n",
    "\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(model, # Classifier\n",
    "                             X_train, # Feature matrix\n",
    "                             y_train, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "\n",
    "# Calculate mean against train set!\n",
    "print(cv_results.mean())\n",
    "\n",
    "# So I have tweaked the 'model' (above) parameters to get the best model, \n",
    "# and can now test against the hold out set. ((Tweaked) Model has to be fitted)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ above cross validation tweaking has improved accuracy (against hold out) by some 1.5%, great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Random Forest approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary libraries\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "# feature importance\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "Confusion matrix:\n",
      "[[5541  211  623]\n",
      " [ 401  352  134]\n",
      " [ 876   90 3652]]\n",
      "Accuracy score:\n",
      "0.8034511784511784\n",
      "\n",
      "RandomForestClassifier relative feature importance:\n",
      "gps_height                                                        0.18494169070974753\n",
      "wpt_age                                                           0.15391620337055825\n",
      "quantity_group                                                    0.13264472838421992\n",
      "construction_year                                                 0.07163853109154457\n",
      "installer                                                        0.059963914864330975\n",
      "waterpoint_type_group                                             0.05692558066029285\n",
      "extraction_type_group                                             0.04878822886000723\n",
      "payment_type                                                      0.04322013346466459\n",
      "region_code                                                      0.041818455837227014\n",
      "population                                                       0.038885754605766945\n",
      "basin                                                             0.03003227218310034\n",
      "scheme_management                                                0.029017195697933092\n",
      "source_type                                                      0.028779881059339787\n",
      "water_quality                                                    0.020349000629465253\n",
      "season_recorded                                                  0.017517196192757958\n",
      "permit                                                            0.01649006351051914\n",
      "management_group                                                 0.012601253380187732\n",
      "public_meeting                                                   0.012469915498336712\n",
      "\n",
      "EXTRA TREE\n",
      "Confusion matrix:\n",
      "[[5459  255  661]\n",
      " [ 396  359  132]\n",
      " [ 918  124 3576]]\n",
      "Accuracy score:\n",
      "0.7907407407407407\n",
      "\n",
      "ExtraTreesClassifier relative feature importance:\n",
      "gps_height                                                        0.18075816156174734\n",
      "quantity_group                                                    0.12497377212596779\n",
      "wpt_age                                                           0.12305182237210759\n",
      "construction_year                                                 0.08180320306705519\n",
      "waterpoint_type_group                                             0.06830308134613769\n",
      "installer                                                         0.05293862803117433\n",
      "payment_type                                                      0.05116064698548452\n",
      "extraction_type_group                                             0.04634684317459189\n",
      "population                                                        0.04083588108784797\n",
      "region_code                                                      0.039059456327085615\n",
      "basin                                                              0.0324679716199152\n",
      "source_type                                                       0.03091112963220675\n",
      "scheme_management                                                 0.02813516081571526\n",
      "water_quality                                                    0.024018544681071397\n",
      "season_recorded                                                   0.02236570788170812\n",
      "permit                                                            0.01990083389433441\n",
      "public_meeting                                                   0.016961870788330828\n",
      "management_group                                                 0.016007284607518112\n"
     ]
    }
   ],
   "source": [
    "# run Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier (sometimes use clf) is initiated\n",
    "classifier=RandomForestClassifier(n_estimators=25, random_state=2)\n",
    "# next step trains the model\n",
    "classifier=classifier.fit(X_train,y_train)\n",
    "# now we apply the classifier to the test data\n",
    "predictions=classifier.predict(X_test)\n",
    "\n",
    "# we look at confusion matrix and accuracy of prediction on test values\n",
    "print(\"RANDOM FOREST\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(y_test,predictions))\n",
    "print(\"Accuracy score:\")\n",
    "print(sklearn.metrics.accuracy_score(y_test, predictions))\n",
    "print()\n",
    "# display the relative importance of each attribute using RandomForestClassifier\n",
    "# make this more readable by having the names of the predictors and having sorted\n",
    "zipped = zip(predictors, classifier.feature_importances_)\n",
    "my_list = list(zipped)\n",
    "my_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "print('RandomForestClassifier relative feature importance:')\n",
    "for item in my_list:\n",
    "    print('{0:42} {1:>42}'.format(item[0], item[1]))\n",
    "\n",
    "# fit an Extra Trees model to the data (instead of Random Forest)\n",
    "model = ExtraTreesClassifier(random_state=2)\n",
    "model.fit(X_train,y_train)\n",
    "predictions=model.predict(X_test)\n",
    "print()\n",
    "print(\"EXTRA TREE\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(y_test,predictions))\n",
    "print(\"Accuracy score:\")\n",
    "print(sklearn.metrics.accuracy_score(y_test, predictions))\n",
    "print()\n",
    "# make this more readable by having the names of the predictors and having sorted\n",
    "zipped = zip(predictors, model.feature_importances_)\n",
    "my_list = list(zipped)\n",
    "my_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "print('ExtraTreesClassifier relative feature importance:')\n",
    "for item in my_list:\n",
    "    print('{0:42} {1:>42}'.format(item[0], item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do random forest with cross-validation and hold out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122053872053872"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest with cross-validation and hold out set\n",
    "model = RandomForestClassifier(n_estimators=50, criterion='entropy', max_depth=18, \n",
    "                               bootstrap=True, oob_score=True, random_state=2)\n",
    "\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(model, # Classifier\n",
    "                             X_train, # Feature matrix\n",
    "                             y_train, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "\n",
    "# Calculate mean against train set!\n",
    "cv_results.mean()\n",
    "\n",
    "# Calculate mean against test set\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random seed set at 2 for all except KNN (where n/a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | Cross-validation | Hold-out set | Accuracy |\n",
    "| ---- | ---- | ---- | ---- |\n",
    "| KNN | no | yes | 68.9% |\n",
    "| Decision tree | no | yes | 74.8-75.2% |\n",
    "| Decision tree | yes | no | 75.8% |\n",
    "| Decision tree | yes | yes | 77.4% |\n",
    "| Random forest | no | yes | 80.3% |\n",
    "| Extra tree | no | yes | 79.1% |\n",
    "| Random forest | yes | yes | 81.2% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How results could be improved\n",
    "> Frequency encoding of variables;<br>\n",
    "> Nearest neighbour for construction year?;<br>\n",
    "> Smaller train set, perhaps model is over-fitted?  (Look how DTree improved with hold out set, when using cross validation)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
