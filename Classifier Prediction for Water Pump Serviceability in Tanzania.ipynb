{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Doc, not Report Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commenced 20 Aug 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Import the two data files (predictors and targets) and merge, with pandas.\n",
    "> 2. Cut down to the predictors to be used. \n",
    "> 3. Create composite variables.\n",
    "> 4. Preliminary data exploration:\n",
    ">> Categorical variables: check number of categories including blanks; create filled bar charts.<br>\n",
    ">> Quantitative variables: get statistics such as mean, median, sd, range, # blanks; create violin or box plots.\n",
    "> 5. Decide on further data mgt., such as: \"rare\" categories, binned categories, delete all rows with blanks/if too many blanks.\n",
    "> 6. Train/test split.\n",
    "> 7. Create decision tree as a baseline reference for random forest.\n",
    "> 8. Create random forest. Tune parameters, consider boosting/bagging, confusion matrix, what is performance?\n",
    "> 9. Predict on test set.\n",
    "> 10. What do I now know? What does everything mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check uniqueness, no duplicate ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 23)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check select_data\n",
    "select_df = pd.read_csv('/Users/RAhmed/data store/Wesleyan_Capstone/select_data.csv')\n",
    "select_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all are unique\n",
    "select_df['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>season_recorded</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>basin</th>\n",
       "      <th>region_code</th>\n",
       "      <th>population</th>\n",
       "      <th>...</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>14/03/11</td>\n",
       "      <td>long_rainy</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>11</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>06/03/13</td>\n",
       "      <td>long_rainy</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>20</td>\n",
       "      <td>280</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25/02/13</td>\n",
       "      <td>short_dry</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>21</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>28/01/13</td>\n",
       "      <td>short_dry</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>90</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>1986</td>\n",
       "      <td>submersible</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>dry</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>13/07/11</td>\n",
       "      <td>long_dry</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id date_recorded season_recorded  gps_height     installer  longitude  \\\n",
       "0  69572      14/03/11      long_rainy        1390         Roman  34.938093   \n",
       "1   8776      06/03/13      long_rainy        1399       GRUMETI  34.698766   \n",
       "2  34310      25/02/13       short_dry         686  World vision  37.460664   \n",
       "3  67743      28/01/13       short_dry         263        UNICEF  38.486161   \n",
       "4  19728      13/07/11        long_dry           0       Artisan  31.130847   \n",
       "\n",
       "    latitude                    basin  region_code  population  \\\n",
       "0  -9.856322               Lake Nyasa           11         109   \n",
       "1  -2.147466            Lake Victoria           20         280   \n",
       "2  -3.821329                  Pangani           21         250   \n",
       "3 -11.155298  Ruvuma / Southern Coast           90          58   \n",
       "4  -1.825359            Lake Victoria           18           0   \n",
       "\n",
       "        ...       construction_year extraction_type_group management_group  \\\n",
       "0       ...                    1999               gravity       user-group   \n",
       "1       ...                    2010               gravity       user-group   \n",
       "2       ...                    2009               gravity       user-group   \n",
       "3       ...                    1986           submersible       user-group   \n",
       "4       ...                       0               gravity            other   \n",
       "\n",
       "   payment_type water_quality quantity_group           source_type  \\\n",
       "0      annually          soft         enough                spring   \n",
       "1     never pay          soft   insufficient  rainwater harvesting   \n",
       "2    per bucket          soft         enough                   dam   \n",
       "3     never pay          soft            dry              borehole   \n",
       "4     never pay          soft       seasonal  rainwater harvesting   \n",
       "\n",
       "  source_class waterpoint_type_group    status_group  \n",
       "0  groundwater    communal standpipe      functional  \n",
       "1      surface    communal standpipe      functional  \n",
       "2      surface    communal standpipe      functional  \n",
       "3  groundwater    communal standpipe  non functional  \n",
       "4      surface    communal standpipe      functional  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select_data is ok. There is a problem with further data as shown here, Should also be 59400 unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check = pd.read_csv('/Users/RAhmed/data store/Wesleyan_Capstone/corrected_data03.csv')\n",
    "# reindex for good luck\n",
    "df_check.reset_index(drop=True, inplace=True)\n",
    "df_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73516    11\n",
       "57806    11\n",
       "72113    11\n",
       "68019    11\n",
       "46000    11\n",
       "33218    11\n",
       "35267    11\n",
       "17326    11\n",
       "61900    11\n",
       "25514    11\n",
       "20952    11\n",
       "60347    11\n",
       "18907    11\n",
       "68487    11\n",
       "66438    11\n",
       "72581    11\n",
       "29212    11\n",
       "33314    11\n",
       "37716    11\n",
       "41510    11\n",
       "35767    11\n",
       "16794    11\n",
       "8790     11\n",
       "33058    11\n",
       "11267    11\n",
       "51467    11\n",
       "6417     11\n",
       "39925    11\n",
       "41970    11\n",
       "74006    11\n",
       "         ..\n",
       "48198     1\n",
       "19544     1\n",
       "21595     1\n",
       "52328     1\n",
       "19576     1\n",
       "27772     1\n",
       "25501     1\n",
       "27548     1\n",
       "19352     1\n",
       "39810     1\n",
       "39522     1\n",
       "45671     1\n",
       "60044     1\n",
       "60076     1\n",
       "68272     1\n",
       "13015     1\n",
       "49897     1\n",
       "60140     1\n",
       "58093     1\n",
       "23290     1\n",
       "31486     1\n",
       "51976     1\n",
       "56074     1\n",
       "66321     1\n",
       "70419     1\n",
       "15126     1\n",
       "21275     1\n",
       "29503     1\n",
       "25469     1\n",
       "71683     1\n",
       "Name: id, Length: 9400, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros 20438 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts = select_df['gps_height'].value_counts()\n",
    "print(\"Zeros\", counts[0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work out the id issue! Why are there 9,400 unique ids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "date_recorded\n",
      "season_recorded\n",
      "gps_height\n",
      "installer\n",
      "longitude\n",
      "latitude\n",
      "basin\n",
      "region_code\n",
      "population\n",
      "public_meeting\n",
      "scheme_management\n",
      "permit\n",
      "construction_year\n",
      "extraction_type_group\n",
      "management_group\n",
      "payment_type\n",
      "water_quality\n",
      "quantity_group\n",
      "source_type\n",
      "source_class\n",
      "waterpoint_type_group\n",
      "status_group\n"
     ]
    }
   ],
   "source": [
    "for col in select_df.columns: print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need helper in dict to find key of maximum value, used in gps_helper\n",
    "def find_dict_max(dict_):\n",
    "    for keys, values in dict_.items():\n",
    "        if values == max(dict_.values()):\n",
    "            return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B. .at, .iat can only take a single value\n",
    "def gps_helper(df):\n",
    "    \"\"\" \n",
    "    takes average height of Euclidian 3 nearest neighbours by distance (lat/long)\n",
    "    trying every short cut to optimise\n",
    "    Not even finding square root of error terms to save a calculation\n",
    "    Notice that you still need to return a df_gps_list for later incorporation\n",
    "    (Setting just not working by any means)\n",
    "    \n",
    "    This version works with putting new value directly into base case df\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in df.index:\n",
    "        # v just progess checking during running of function\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        if df.iat[i, 3] != 0: \n",
    "           pass\n",
    "            \n",
    "        else: \n",
    "            # neighbours = {index: distance, ...} - are dummy keys / values that get replaced\n",
    "            neighbours = {999999: 9999, 999998: 9998, 999997: 9997}\n",
    "            for j in df.index: \n",
    "                if j != i: \n",
    "                    euclidian_dist = ((df.iat[i, 6] - df.iat[j, 6])**2 + (df.iat[i, 5] - df.iat[j, 5])**2)\n",
    "    \n",
    "                    if euclidian_dist < max(neighbours.values()):\n",
    "                        # if yes, need to remove max distance so far and update  with smaller distance\n",
    "                        neighbours.pop(find_dict_max(neighbours))\n",
    "                        neighbours.update({j: euclidian_dist})\n",
    " \n",
    "            heights = []\n",
    "            for k in neighbours.keys():\n",
    "                heights.append(df['gps_height'][k])\n",
    "            if len(heights) != 0:\n",
    "                df.iat[i, 3] = sum(heights) / len(heights)\n",
    "            else: \n",
    "                df.iat[i, 3] = 0\n",
    "\n",
    "    zero_count = 0\n",
    "    for m in range(df.shape[0]):\n",
    "        if df.iat[m, 3] == 0:\n",
    "            zero_count += 1\n",
    "\n",
    "    print(\"number of zero heights is: {}\".format(zero_count))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial zeros 20399\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "number of zero heights is: 618\n",
      "remaining zeros 20377\n",
      "31.025849103927612 s\n"
     ]
    }
   ],
   "source": [
    "# template\n",
    "start = time.time()\n",
    "print(\"initial zeros\", df['gps_height'].value_counts()[0])\n",
    "df[:2000] = gps_helper(df[:2000])\n",
    "counts = df['gps_height'].value_counts()\n",
    "stop = time.time()\n",
    "print(\"remaining zeros\", df['gps_height'].value_counts()[0])\n",
    "print(stop - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d16fea173e1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgps_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3377c71fd342>\u001b[0m in \u001b[0;36mgps_helper\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m            \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iget_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_box_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "df[50:100] = gps_helper(df[50:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Preliminary data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Roland Jeannier's code.\n",
    "https://medium.com/@rtjeannier/pandas-101-fbb5bf86a9bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_helper(df):\n",
    "   dict_list = []\n",
    "   for col in df.columns:\n",
    "       data = df[col]\n",
    "       dict_ = {}\n",
    "       # The null count for a column. \n",
    "       dict_.update({\"null_count\" : data.isnull().sum()})\n",
    "       # Counting the unique values in a column\n",
    "       dict_.update({\"unique_count\" : len(data.unique())})\n",
    "       # Finding the types of data in the column\n",
    "       # This is useful for finding out potential problems with type mismatches\n",
    "       dict_.update({\"data_type\" : set([type(d).__name__ for d in data])})\n",
    "       #dict_.update({\"score\" : match[1]})\n",
    "       dict_list.append(dict_)\n",
    "   eda_df = pd.DataFrame(dict_list)\n",
    "   eda_df.index = df.columns\n",
    "   eda_df.sort_values(by=['null_count', 'unique_count'], ascending=[True, False], inplace=True)\n",
    "       \n",
    "   return eda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/RAhmed/data store/Wesleyan_Capstone/corrected_data03.csv')\n",
    "# reindex for good luck\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# run eda_helper\n",
    "print(eda_helper(df))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B. Need to make most predictors into a categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'installer', 'basin', 'region_code', \n",
    "             'population', 'public_meeting', 'scheme_management', 'permit',\n",
    "             'extraction_type_group', 'management_group', 'payment_type', \n",
    "              'water_quality', 'quantity_group', 'source_type', \n",
    "             'source_class', 'waterpoint_type_group', 'status_group'}\n",
    "\n",
    "for item in categories:\n",
    "    select_data[item] = select_data[item].astype('category')\n",
    "# check types\n",
    "select_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To Do:** Run construction_year_helper on the complete data set that you want to use. No need to run twice as seems to have no zero entries. (Shouldn't do by its construction.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now read in corrected_data03.csv as a dataframe. Use eda_helper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an seeming anomaly: says there were 9400 unique ids. However, I reindexed and still same. Also, I  visually checked, indices are unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following check confirms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can you see globally?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lost categorisation - need to redo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null counts only in some places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['longitude'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_counts = df['latitude'].value_counts()\n",
    "lat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gps_height'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['population'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['extraction_type_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['water_quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population needs bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['permit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['basin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['management_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quantity_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['season_recorded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['waterpoint_type_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['permit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['installer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scheme_management'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['public_meeting'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['population'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In retrospect, below is too involved, can be simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population_needs bins\n",
    "# look at sorting first to visually inspect potential bins\n",
    "popn_df = df['population'].value_counts().items()\n",
    "temp = {}\n",
    "for k, v in popn_df:\n",
    "    temp.update({k:v})\n",
    "sorted(temp.items(), key=lambda x: x[0], reverse=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good 'category' bins look like 0, 1, 2-20, 20-30, 30-50, 50-100, 100-200, 200-300, 300-500, 500-1000, > 1000\n",
    "# can do that after. Method will be create a category with a string name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â function to create bins for population variable\n",
    "def popn_bins(population):\n",
    "    if population == 0:\n",
    "        return '0'\n",
    "    elif population == 1:\n",
    "        return '1'\n",
    "    elif 2 <= population <  20:\n",
    "        return '20'\n",
    "    elif 20 <= population <  30:\n",
    "        return '30'\n",
    "    elif 30 <= population <  50:\n",
    "        return '50'\n",
    "    elif 50 <= population <  100:\n",
    "        return '100'\n",
    "    elif 100 <= population <  200:\n",
    "        return '100'\n",
    "    elif 200 <= population <  300:\n",
    "        return '100'\n",
    "    elif 300 <= population <  500:\n",
    "        return '500'\n",
    "    elif 500 <= population <  1000:\n",
    "        return '1000'\n",
    "    else:\n",
    "        return '1000+'\n",
    "\n",
    "# for item in df.population:\n",
    "#     print(item, type(item))\n",
    "#Â run function on df\n",
    "df.population = df.population.apply(popn_bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.population[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot of work on installer needed.\n",
    "# look at sorting first to visually inspect potential bins\n",
    "installer_df = df['installer'].value_counts().items()\n",
    "temp1 = {}\n",
    "for k, v in installer_df:\n",
    "    temp1.update({k:v})\n",
    "sorted(temp1.items(), key=lambda x: x[0], reverse=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_dict = {'Arisan': {'Arisan', 'Arian', 'Artisan'}, 'Government': {'Government', 'government', 'govt.'}, 'Japan': {'Japan', 'Japan Government'}}\n",
    "\n",
    "def allocator(name):\n",
    "    for key, value in test_dict.items():\n",
    "        temp = []\n",
    "        for value1 in value:\n",
    "            temp.append(value1)\n",
    "        if name in temp:\n",
    "            return key\n",
    "        \n",
    "    return name\n",
    "        \n",
    "print(allocator('Arian'))\n",
    "print(allocator('Cheese'))\n",
    "print(allocator('govt.'))\n",
    "print(allocator('Henry'))\n",
    "print(allocator('Japan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create installer dictionary\n",
    "installer_dict = {'Artisan': {'Arisan', 'Arian', 'Artisan'}, \n",
    "                  'Babu Sajini': {'Babu Sajini', 'Babu Sajin'},\n",
    "                  'China': {'CHINA'},\n",
    "                  'CJEJOW': {'CJEJOW', 'CJEJ0', 'CJEJOW CONSTRUCTION'},\n",
    "                  'Concern': {'Concern', 'Concen'},\n",
    "                  'DANIDA' : {'DANIDA','DANIAD', 'DANID','DANIDS'},\n",
    "                  'DASIP' : {'DASIP', 'DASP', 'DASSIP'},\n",
    "                  'DBSPE': {'DBSPE', 'DBSP'},\n",
    "                  'DW': {'DW', 'DW#', 'DWE & LWI', 'DWR', 'DWW'},\n",
    "                  'District Water Department': {'District Water Department', 'Distric Water Department', \n",
    "                                                'District water department'},\n",
    "                  'Dr. Matobola': {'Dr. Matobola', 'Dr.Matobola'},\n",
    "                  'Dr. Matomola': {'Dr. Matomola','Dr.Matomola'},\n",
    "                  'EL': {'EL', 'ELCT'},\n",
    "                  'Egypt': {'People from Egypt', 'Tanz Egypt technical coopera', 'Tanzania/ Egypt', \n",
    "                            'Wizra ya maji na egypt'},\n",
    "                  'Fin Water': {'Fin Water', 'FIN WATER', 'FINI WATER', 'FINI Water','FW', \n",
    "                                'Fin water', 'FinW','FinWate','FinWater', 'Fini Water', \n",
    "                                'Fini water', 'Finland Government', 'Finwater'},\n",
    "                  'Government': {'Government', 'GOVERNMENT', 'Government and Community', 'Central government',\n",
    "                                 'Wizara  ya maji', 'Wizara ya maji', 'wizara ya maji'},\n",
    "                  'GRA' : {'GRA','GRA TZ MUSOMA'},\n",
    "                  'GRUMETI':{'GRUMETI', 'GRUMET'},\n",
    "                  'Grobal resource alliance': {'Grobal resource alliance', 'Grobal resource  alliance'},\n",
    "                  'Hesawa': {'Hesawa', 'HESAWA', 'Hasawa','Hesawz', 'Hesewa'},\n",
    "                  'Individuals': {'Individuals', 'INDIVIDUALS'},\n",
    "                  'Institution': {'Institution', 'Insititutiona'},\n",
    "                  'Japan Government': {'Japan Government', 'JAPAN EMBASSY', 'JICA','JAICA', 'Jaica', 'JSICA','Jika'},\n",
    "                  'Jeshi la Wokovu': {'Jeshi la Wokovu', 'Jeshi la wokovu', 'Jeshi la wokovu [cida]'},\n",
    "                  'KARUMBA BUILDING COMPANY LTD': {'KARUMBA BUILDING COMPANY LTD', 'KARUMBA BIULDIN',\n",
    "                                                  'KARUMBA BIULDING COMPANY LTD','KARUMBA BIULDING CONTRACTOR'},\n",
    "                  'KOBERG': {'KOBERG', 'KOBERG Contractor'},\n",
    "                  'KYASHA ENTERPR': {'KYASHA ENTERPR', 'KYASHA ENTREPR'},\n",
    "                  'LWI': {'LWI', 'LWI &CENTRAL GOVERNMENT'},\n",
    "                  'MACK DONALD CO LTD': {'MACK DONALD CO LTD','MACK DONALD CONTRACTOR', 'MACK DONALD CONTRSCTOR'},\n",
    "                  'MKONGO CONSTRUCTION': {'MKONGO CONSTRUCTION', 'MKON CONSTRUCTION', 'MKONG CONSTRUCTION',\n",
    "                                         'MKONGO BUILDING CONTRACTOR'},\n",
    "                  'MTUWASA': {'MTUWASA', 'MTUWASA and Community'},\n",
    "                  'MWAKI CONTRACTOR': {'MWAKI CONTRACTOR', 'MWAKI CONTRACTO'},\n",
    "                  'Makonde': {'Makonde', 'Makonde water Population', 'Makonde water population','Makonde water supply'},\n",
    "                  'Maswi company': {'Maswi company', 'Maswi'},\n",
    "                  'Private': {'Private', 'Privat'},\n",
    "                  'RC church': {'RC church', 'R.C', 'RC CATHORIC', 'RC/Mission', 'Roman', 'Cathoric', 'rc ch'},\n",
    "                  'Region Water Department': {'Region Water Department', 'Region water', 'Region water Department', \n",
    "                                              'Regional Water'},\n",
    "                  'SAXON BUILDING CONTRACTORS': {'SAXON BUILDING CONTRACTORS', 'SAXON  BUILDING CONTRACTOR',\n",
    "                                                 'SAXON BUILDING CONTRACTOR'},\n",
    "                  'TASAF': {'TASAF', 'TASA', 'TASAF 1', 'TASAF and Comunity', 'TASAF and MMEM', \n",
    "                            'TASAFcitizen and LGA', 'TASF', 'TASSAF', 'Tasaf', 'Tasaf and Lga'},\n",
    "                  'Taes': {'Taes', 'Taees'},\n",
    "                  'TUKWALE ENTERP': {'TUKWALE ENTERP', 'TUKWARE ENTERP'},\n",
    "                  'UMOJA DRILLING': {'UMOJA DRILLING', 'UMOJA DRILLING CONSTRUCTION',\n",
    "                                     'UMOJA DRILLING CONTRACTOR','UMOJA DRILLING CONTRUCTO'},\n",
    "                  'UNICEF': {'UNICEF', 'UNICRF','Unicef','Unisef'},\n",
    "                  'VC': {'VC', 'VCIF'},\n",
    "                  'VIFAFI': {'VIFAFI', 'VIFAI'},\n",
    "                  'VITECOS': {'VITECOS','VITECOS INVEST', 'VTECOS'},\n",
    "                  'Village Govt': {'Village Govt','Village government', 'Village govt', \n",
    "                                   'Village local contractor', 'Village water committee', 'Subvillage'},\n",
    "                  'WORLD BANK': {'WORLD BANK', 'W', 'W/', 'WORLD NK', 'WOULD BANK', 'World bank'},\n",
    "                  'Water users Group': {'Water use Group','Water user Group','Water users Group'},\n",
    "                  'Zao': {'Zao','Zao water spring','Zao water spring X'}\n",
    "                 }\n",
    "\n",
    "print(len(installer_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with name of dictionary included. (Might be needed for actual .apply(...))\n",
    "test_dict2 = {'Arisan': {'Arisan', 'Arian', 'Artisan'}, 'Government': {'Government', 'government', 'govt.'}, 'Japan': {'Japan', 'Japan Government'}}\n",
    "\n",
    "def allocator2(name, names_dict):\n",
    "    for key, value in names_dict.items():\n",
    "        temp = []\n",
    "        for value1 in value:\n",
    "            temp.append(value1)\n",
    "        if name in temp:\n",
    "            return key\n",
    "        \n",
    "    return name\n",
    "        \n",
    "print(allocator2('Arian', test_dict2))\n",
    "print(allocator2('Cheese', test_dict2))\n",
    "print(allocator2('govt.', test_dict2))\n",
    "print(allocator2('Henry', test_dict2))\n",
    "print(allocator2('Japan', test_dict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got from 466 categories to 50, much better!\n",
    "\n",
    "Next is to turn all of the remaining 1s (and 2s) into another category.  Needs a function to apply after the above function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test = [{'installer': 'Japan', 'year': 2015},\n",
    "        {'installer': 'Japan', 'year': 2017},\n",
    "        {'installer': 'Egypt', 'year': 2015},\n",
    "        {'installer': 'Spain', 'year': 2014},\n",
    "        {'installer': 'erik', 'year': 2014},\n",
    "        {'installer': 'a_village', 'year': 2013},\n",
    "        {'installer': 'Spain', 'year': 2015},\n",
    "        {'installer': 'Egypt', 'year': 2012},\n",
    "        {'installer': 'Egypt', 'year': 2014},\n",
    "        {'installer': 'Japan', 'year': 2014},\n",
    "       ]\n",
    "test_df = pd.DataFrame(test)\n",
    "test_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.installer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = test_df.installer.value_counts()\n",
    "print(type(z))\n",
    "for i in z.index:\n",
    "    print(i)\n",
    "z.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in test_df.installer:\n",
    "    if test_df.installer.value_counts()[name] == 1:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below will work on the df column with apply method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name(name):\n",
    "    if test_df.installer.value_counts()[name] < 3:\n",
    "        return 'one-offs'\n",
    "    else:\n",
    "        return name\n",
    "test_df.installer = test_df.installer.apply(change_name)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name2(name, df):\n",
    "    if df.installer.value_counts()[name] < 3:\n",
    "        return 'one-offs'\n",
    "    else:\n",
    "        return name\n",
    "test_df.installer = test_df.installer.apply(lambda x: change_name2(x, test_df))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run installer functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we reduce number of installer categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.installer = df.installer.apply(lambda name: allocator2(name, installer_dict))\n",
    "df['installer'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â an easy way, partial\n",
    "nums_dict = {}\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "for name in df['installer'].value_counts().index:\n",
    "    if df['installer'].value_counts()[name] == 1:\n",
    "        count1 += 1\n",
    "    if df['installer'].value_counts()[name] == 2:\n",
    "        count2 += 1\n",
    "    if df['installer'].value_counts()[name] == 3:\n",
    "        count3 += 1\n",
    "    if df['installer'].value_counts()[name] == 4:\n",
    "        count4 += 1\n",
    "\n",
    "print(('1', count1), ('2', count2), ('3', count3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create counts in pandas properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "number_installed  = []\n",
    "for index in df['installer'].value_counts():\n",
    "    number_installed.append(index)\n",
    "count_installed = pd.DataFrame.from_dict(Counter(number_installed), orient=\"index\")\n",
    "count_installed\n",
    "# ^ count_installed is in format: col0 = how many have you installed; col1 = number of orgs who have installed this many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable to have a category of one_off if you installed only one water point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_offs = []\n",
    "names = df['installer'].value_counts().index\n",
    "for name in names:\n",
    "    if df['installer'].value_counts()[name] == 1:\n",
    "        one_offs.append(name)\n",
    "len(one_offs)\n",
    "print(one_offs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Islamic' in df.installer.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_one_off(name):\n",
    "    if name in one_offs:\n",
    "        return 'one_off'\n",
    "    else: \n",
    "        return name\n",
    "\n",
    "df.installer = df.installer.apply(is_one_off)\n",
    "'Islamic' in df.installer.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'one_off' in df.installer.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ So that worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun eda_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eda_helper(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this good data!\n",
    "# df.to_csv('/Users/RAhmed/data store/Wesleyan_Capstone/corrected_data02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply wpt_age globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wpt_age = df['date_recorded'].apply(year_convert) - df['construction_year']\n",
    "df_wpt_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(14, 'wpt_age', df_wpt_age)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this update\n",
    "# df.to_csv('/Users/RAhmed/data store/Wesleyan_Capstone/corrected_data03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'extraction_type_group', 'region_code', 'population', 'water_quality', 'payment_type',\n",
    "              'source_type', 'basin', 'management_group', 'quantity_group', 'season_recorded', \n",
    "              'waterpoint_type_group', 'source_class', 'status_group', 'permit', 'installer', \n",
    "              'public_meeting', 'scheme_management', 'region_code'\n",
    "            }\n",
    "\n",
    "for item in categories:\n",
    "    df[item] = df[item].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eda_helper(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_xlabel('X_axi',fontsize=0.1)\n",
    "ax = sns.countplot(x='extraction_type_group', hue='status_group', data=df)\n",
    "ax.figure.savefig(\"output0.png\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='region_code', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='population', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='water_quality', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='payment_type', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='source_type', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='basin', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='management_group', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='quantity_group', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='season_recorded', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='waterpoint_type_group', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='source_class', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='permit', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_xlabel('X_axi',fontsize=0.2)\n",
    "ax = sns.countplot(x='installer', hue='status_group', data=df)\n",
    "ax.figure.savefig(\"output1.png\", dpi = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_xlabel('X_axi',fontsize=0.4)\n",
    "\n",
    "sns.axes_style()\n",
    "# sns.set_context(\"notebook\", font_scale=.5, rc={\"lines.linewidth\": 2.5})\n",
    "ax = sns.countplot(x='scheme_management', hue='status_group', data=df)\n",
    "ax.figure.savefig(\"output1.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig(\"output.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='public_meeting', hue='status_group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('installer')['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in range([start], stop[, step])\n",
    "for r in range(1000, 1100, 1): print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
